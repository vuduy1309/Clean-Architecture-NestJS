// /**
//  * WORKER THREADS - CHI TIáº¾T TOÃ€N DIá»†N
//  * 
//  * Ná»™i dung:
//  * 1. Worker threads lÃ  gÃ¬
//  * 2. Khi nÃ o dÃ¹ng worker threads
//  * 3. Kiáº¿n trÃºc vÃ  cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng
//  * 4. CÃ¡ch táº¡o vÃ  sá»­ dá»¥ng worker threads
//  * 5. Giao tiáº¿p giá»¯a main thread vÃ  worker thread
//  * 6. So sÃ¡nh: Main thread vs Worker thread vs Thread pool vs Cluster
//  * 7. Performance benchmarks
//  * 8. Best practices
//  * 9. Common pitfalls vÃ  cÃ¡ch fix
//  */

// // ============================================================================
// // PHáº¦N 1: WORKER THREADS LÃ€ GÃŒ?
// // ============================================================================

// /**
//  * Worker Threads:
//  * 
//  * LÃ  má»™t cÃ¡ch Ä‘á»ƒ cháº¡y JavaScript code trÃªn multiple threads
//  * trong cÃ¹ng má»™t process.
//  * 
//  * Má»—i worker thread lÃ  má»™t V8 instance Ä‘á»™c láº­p:
//  * - CÃ³ own JavaScript execution context
//  * - CÃ³ own event loop
//  * - CÃ³ own memory space (heap)
//  * - Cháº¡y song song vá»›i main thread
//  * 
//  * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//  * â”‚            Node.js Process                     â”‚
//  * â”‚                                                 â”‚
//  * â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
//  * â”‚  â”‚ Main Thread      â”‚  â”‚ Worker Thread 1  â”‚   â”‚
//  * â”‚  â”‚ (Your app code)  â”‚  â”‚ (CPU task)       â”‚   â”‚
//  * â”‚  â”‚                  â”‚  â”‚                  â”‚   â”‚
//  * â”‚  â”‚ V8 instance      â”‚  â”‚ V8 instance      â”‚   â”‚
//  * â”‚  â”‚ Event loop       â”‚  â”‚ Event loop       â”‚   â”‚
//  * â”‚  â”‚ Heap             â”‚  â”‚ Heap             â”‚   â”‚
//  * â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
//  * â”‚                                                 â”‚
//  * â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
//  * â”‚  â”‚ Worker Thread 2  â”‚  â”‚ Worker Thread 3  â”‚   â”‚
//  * â”‚  â”‚ (CPU task)       â”‚  â”‚ (CPU task)       â”‚   â”‚
//  * â”‚  â”‚                  â”‚  â”‚                  â”‚   â”‚
//  * â”‚  â”‚ V8 instance      â”‚  â”‚ V8 instance      â”‚   â”‚
//  * â”‚  â”‚ Event loop       â”‚  â”‚ Event loop       â”‚   â”‚
//  * â”‚  â”‚ Heap             â”‚  â”‚ Heap             â”‚   â”‚
//  * â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
//  * â”‚                                                 â”‚
//  * â”‚  [Shared memory] (optional)                   â”‚
//  * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//  */

// // ============================================================================
// // PHáº¦N 2: KHI NÃ€O DÃ™NG WORKER THREADS?
// // ============================================================================

// /**
//  * âœ“ DÃ™NG WORKER THREADS KHI:
//  * 
//  * 1. CPU-Intensive Tasks (tÃ­nh toÃ¡n náº·ng)
//  *    - Fibonacci calculation
//  *    - Cryptography
//  *    - Image processing
//  *    - Machine learning inference
//  *    - Data processing/compression
//  *    - Video encoding/decoding
//  * 
//  * 2. TÃ¡c vá»¥ cháº¡y lÃ¢u cÃ³ thá»ƒ cháº·n main thread
//  *    - Heavy JSON parsing
//  *    - Large file processing
//  *    - Complex algorithm
//  * 
//  * 3. Muá»‘n táº­n dá»¥ng multi-core CPU
//  *    - CÃ³ 8 cores â†’ CÃ³ thá»ƒ cháº¡y 8 workers song song
//  * 
//  * 4. Muá»‘n giá»¯ main thread ráº£nh
//  *    - Main thread xá»­ lÃ½ HTTP requests
//  *    - Worker threads xá»­ lÃ½ CPU tasks
//  *    - Non-blocking experience
//  */

// /**
//  * âŒ KHÃ”NG DÃ™NG WORKER THREADS KHI:
//  * 
//  * 1. I/O-bound operations
//  *    âŒ Database queries (dÃ¹ng async/await)
//  *    âŒ File reading (dÃ¹ng fs.promises)
//  *    âŒ HTTP requests (dÃ¹ng async/await)
//  *    (Node.js Ä‘Ã£ handle cÃ¡i nÃ y hiá»‡u quáº£ vá»›i event loop)
//  * 
//  * 2. Simple tasks
//  *    âŒ Basic calculations
//  *    âŒ JSON parsing (nhá»)
//  *    (Overhead cá»§a worker creation > benefit)
//  * 
//  * 3. Shared state complexity
//  *    âŒ Multiple workers cáº§n access shared data
//  *    (GÃ¢y synchronization problems)
//  */

// // ============================================================================
// // PHáº¦N 3: KIáº¾N TRÃšC WORKER THREADS
// // ============================================================================

// /**
//  * THREAD MODEL:
//  * 
//  * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//  * â”‚           Main Thread (Your App)               â”‚
//  * â”‚                                                â”‚
//  * â”‚ const worker = new Worker('./heavy.js')       â”‚
//  * â”‚ worker.postMessage({ data: ... })             â”‚
//  * â”‚ worker.on('message', callback)                â”‚
//  * â”‚                                                â”‚
//  * â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
//  * â”‚ â”‚ Worker Thread (Heavy.js)                 â”‚  â”‚
//  * â”‚ â”‚                                          â”‚  â”‚
//  * â”‚ â”‚ import { parentPort } from ...           â”‚  â”‚
//  * â”‚ â”‚ parentPort.on('message', async msg => {  â”‚  â”‚
//  * â”‚ â”‚   const result = doHeavyWork(msg.data)  â”‚  â”‚
//  * â”‚ â”‚   parentPort.postMessage(result)        â”‚  â”‚
//  * â”‚ â”‚ })                                       â”‚  â”‚
//  * â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
//  * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//  * 
//  * 
//  * GIAO TIáº¾P:
//  * 
//  * postMessage() â† Data marshalling (serialize)
//  * â†“
//  * Structured clone algorithm (copy data)
//  * â†“
//  * Worker receives message
//  * â†“
//  * Worker processes
//  * â†“
//  * Worker postMessage() â† Serialize again
//  * â†“
//  * Main thread receives
//  * 
//  * âš ï¸ QUAN TRá»ŒNG: Data Ä‘Æ°á»£c COPY, khÃ´ng SHARE
//  *    (Ngoáº¡i trá»« khi dÃ¹ng SharedArrayBuffer)
//  */

// // ============================================================================
// // PHáº¦N 4: VÃ Dá»¤ CODE - FIBONACCI
// // ============================================================================

// /**
//  * Use case: TÃ­nh Fibonacci(40) - CPU intensive
//  * 
//  * Fibonacci(40) = 102,334,155
//  * Thá»i gian: ~1-2 giÃ¢y (tuá»³ hardware)
//  */

// // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// // main.ts - Main thread
// // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// import { Worker } from 'worker_threads';
// import path from 'path';

// async function calculateFibonacciWithWorker(n: number): Promise<number> {
//   return new Promise((resolve, reject) => {
//     // Táº¡o worker thread tá»« file fibonacci.worker.ts
//     const worker = new Worker(path.join(__dirname, 'fibonacci.worker.ts'));

//     // Gá»­i data Ä‘áº¿n worker
//     worker.postMessage({ n });

//     // Láº¯ng nghe káº¿t quáº£ tá»« worker
//     worker.on('message', result => {
//       console.log(`âœ“ Worker returned: ${result}`);
//       worker.terminate(); // Giáº¿t worker (free resources)
//       resolve(result);
//     });

//     // Handle error
//     worker.on('error', reject);

//     // Handle unexpected exit
//     worker.on('exit', code => {
//       if (code !== 0) {
//         reject(new Error(`Worker exited with code ${code}`));
//       }
//     });

//     // Timeout (náº¿u worker bá»‹ hang)
//     setTimeout(() => {
//       worker.terminate();
//       reject(new Error('Worker timeout'));
//     }, 10000); // 10 seconds
//   });
// }

// async function demonstrateFibonacci() {
//   console.log('=== Fibonacci Calculation ===\n');

//   // Test 1: Vá»›i worker thread
//   console.log('Test 1: Using Worker Thread');
//   const start1 = Date.now();
//   const result1 = await calculateFibonacciWithWorker(40);
//   const time1 = Date.now() - start1;
//   console.log(`Result: ${result1}, Time: ${time1}ms\n`);

//   // Test 2: KhÃ´ng dÃ¹ng worker (blocking main thread)
//   console.log('Test 2: Blocking Main Thread (direct calculation)');
//   const start2 = Date.now();
//   const result2 = fibonacciSync(40);
//   const time2 = Date.now() - start2;
//   console.log(`Result: ${result2}, Time: ${time2}ms\n`);

//   // Observations:
//   // - Thá»i gian tÃ­nh toÃ¡n gáº§n nhÆ° nhau (~1500-2000ms)
//   // - NhÆ°ng vá»›i worker, main thread KHÃ”NG CHáº¶N
//   // - CÃ³ thá»ƒ xá»­ lÃ½ requests khÃ¡c trong khi worker tÃ­nh toÃ¡n
// }

// function fibonacciSync(n: number): number {
//   if (n <= 1) return n;
//   return fibonacciSync(n - 1) + fibonacciSync(n - 2);
// }

// // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// // fibonacci.worker.ts - Worker thread code
// // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// /**
//  * File nÃ y cháº¡y trong worker thread, KHÃ”NG trong main thread
//  * 
//  * Äá»ƒ import Ä‘Ãºng:
//  * import { parentPort, workerData } from 'worker_threads';
//  */

// // fibonacci.worker.ts content:
// /*
// import { parentPort } from 'worker_threads';

// function fibonacci(n: number): number {
//   if (n <= 1) return n;
//   return fibonacci(n - 1) + fibonacci(n - 2);
// }

// // Láº¯ng nghe message tá»« main thread
// parentPort.on('message', (message) => {
//   console.log(`Worker: Nháº­n yÃªu cáº§u tÃ­nh fibonacci(${message.n})`);
  
//   const result = fibonacci(message.n);
  
//   console.log(`Worker: TÃ­nh xong, gá»­i káº¿t quáº£`);
//   // Gá»­i káº¿t quáº£ vá» main thread
//   parentPort.postMessage(result);
// });

// // Hoáº·c, ngay khi worker Ä‘Æ°á»£c táº¡o, nháº­n workerData:
// // const result = fibonacci(workerData.n);
// // parentPort.postMessage(result);
// */

// // ============================================================================
// // PHáº¦N 5: VÃ Dá»¤ CODE - WORKER POOL
// // ============================================================================

// /**
//  * Worker Pool: Táº¡o sáºµn N workers, tÃ¡i sá»­ dá»¥ng chÃºng
//  * 
//  * Lá»£i Ã­ch:
//  * - TrÃ¡nh overhead cá»§a viá»‡c create/destroy workers
//  * - CÃ³ thá»ƒ xá»­ lÃ½ multiple tasks Ä‘á»“ng thá»i
//  * - Manage resources hiá»‡u quáº£
//  */

// class WorkerPool {
//   private workers: Worker[] = [];
//   private queue: Array<{
//     task: any;
//     resolve: (value: any) => void;
//     reject: (error: any) => void;
//   }> = [];
//   private workerPath: string;
//   private poolSize: number;

//   constructor(workerPath: string, poolSize: number = 4) {
//     this.workerPath = workerPath;
//     this.poolSize = poolSize;
//     this.initialize();
//   }

//   private initialize() {
//     for (let i = 0; i < this.poolSize; i++) {
//       this.createWorker();
//     }
//   }

//   private createWorker() {
//     const worker = new Worker(this.workerPath);

//     worker.on('message', result => {
//       const job = this.queue.shift();
//       if (job) {
//         job.resolve(result);
//         // Worker ráº£nh, xá»­ lÃ½ task tiáº¿p theo
//         this.processQueue(worker);
//       } else {
//         // KhÃ´ng cÃ³ task trong queue, worker chá»
//         this.workers.push(worker);
//       }
//     });

//     worker.on('error', error => {
//       const job = this.queue.shift();
//       if (job) {
//         job.reject(error);
//       }
//     });

//     this.workers.push(worker);
//   }

//   private processQueue(worker: Worker) {
//     const job = this.queue.shift();
//     if (job) {
//       worker.postMessage(job.task);
//     } else {
//       this.workers.push(worker);
//     }
//   }

//   async runTask(task: any): Promise<any> {
//     return new Promise((resolve, reject) => {
//       const availableWorker = this.workers.pop();

//       if (availableWorker) {
//         // CÃ³ worker ráº£nh, gá»­i task ngay
//         availableWorker.postMessage(task);
//         availableWorker.once('message', result => {
//           resolve(result);
//           this.workers.push(availableWorker);
//           this.processQueue(availableWorker);
//         });
//         availableWorker.once('error', reject);
//       } else {
//         // KhÃ´ng cÃ³ worker ráº£nh, queue task
//         this.queue.push({ task, resolve, reject });
//       }
//     });
//   }

//   terminate() {
//     this.workers.forEach(worker => worker.terminate());
//   }
// }

// // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// // Sá»­ dá»¥ng worker pool
// // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// async function demonstrateWorkerPool() {
//   console.log('=== Worker Pool Demo ===\n');

//   const pool = new WorkerPool(
//     path.join(__dirname, 'fibonacci.worker.ts'),
//     4 // 4 workers
//   );

//   // 10 fibonacci tasks
//   const tasks = Array.from({ length: 10 }, (_, i) => ({
//     n: 35 + i,
//   }));

//   console.log(`Xá»­ lÃ½ ${tasks.length} tasks vá»›i 4 workers\n`);

//   const start = Date.now();

//   // Gá»­i táº¥t cáº£ tasks tá»›i pool
//   const promises = tasks.map(task => pool.runTask(task));

//   // Chá» táº¥t cáº£ hoÃ n thÃ nh
//   const results = await Promise.all(promises);

//   const time = Date.now() - start;

//   console.log(`\nHoÃ n thÃ nh ${results.length} tasks trong ${time}ms`);
//   console.log(`Káº¿t quáº£: ${results}`);

//   pool.terminate();

//   /**
//    * Timeline:
//    * 
//    * T=0ms:    Gá»­i 4 tasks (workers 1-4)
//    * T=0.1ms:  Gá»­i 4 tasks tiáº¿p theo (Ä‘á»£i workers ráº£nh)
//    * T=0.2ms:  Gá»­i 2 tasks cuá»‘i cÃ¹ng
//    * 
//    * T=~1000ms: Workers 1-4 xong (fibonacci 35-38)
//    *            NÃ³ xá»­ lÃ½ tasks 5-8
//    * 
//    * T=~2000ms: Táº¥t cáº£ 10 tasks xong
//    * 
//    * So sÃ¡nh:
//    * - Sequential (1 worker): 10 Ã— 1000ms = 10 seconds
//    * - Parallel (4 workers): 10 Ã— 1000ms / 4 â‰ˆ 2.5 seconds
//    * - Speedup: 4x
//    */
// }

// // ============================================================================
// // PHáº¦N 6: SHARED MEMORY - ADVANCED
// // ============================================================================

// /**
//  * BÃ¬nh thÆ°á»ng, data Ä‘Æ°á»£c COPY giá»¯a threads (structured clone)
//  * 
//  * NhÆ°ng náº¿u xá»­ lÃ½ large data (GB), copy ráº¥t cháº­m!
//  * 
//  * Giáº£i phÃ¡p: SharedArrayBuffer
//  * - Share memory trá»±c tiáº¿p
//  * - KhÃ´ng cáº§n copy
//  * - Cáº§n synchronization (Atomics)
//  */

// function sharedMemoryExample() {
//   // Main thread
//   const buffer = new SharedArrayBuffer(1024 * 1024); // 1MB
//   const array = new Int32Array(buffer);

//   // Gá»­i buffer tá»›i worker (transfer, khÃ´ng copy)
//   const worker = new Worker('./processor.worker.js');
//   worker.postMessage({ buffer }, [buffer]); // [buffer] = transferList

//   // Khi worker update buffer, main thread cÃ³ thá»ƒ Ä‘á»c
//   // NhÆ°ng cáº§n dÃ¹ng Atomics Ä‘á»ƒ synchronization

//   /**
//    * Khi dÃ¹ng SharedArrayBuffer:
//    * 
//    * âœ“ TrÃ¡nh data copy (nhanh hÆ¡n)
//    * âŒ Phá»©c táº¡p hÆ¡n (cáº§n atomic operations)
//    * âŒ Security risk (tiá»m nÄƒng side-channel attacks)
//    * 
//    * Má»¥c Ä‘Ã­ch: Xá»­ lÃ½ large data (images, audio, video)
//    */
// }

// // ============================================================================
// // PHáº¦N 7: SO SÃNH - WORKER THREADS vs ALTERNATIVES
// // ============================================================================

// /**
//  * â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
//  * â•‘ MAIN THREAD (No threading)                                    â•‘
//  * â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
//  * â•‘ Kiáº¿n trÃºc:  Single-threaded                                   â•‘
//  * â•‘ Táº¡o cost:   N/A                                               â•‘
//  * â•‘ Memory:     Low                                               â•‘
//  * â•‘ Complexity: Simple                                            â•‘
//  * â•‘ Use case:   I/O-bound (network, database)                    â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Pros:                                                         â•‘
//  * â•‘ + Event loop handles thousands of concurrent I/O              â•‘
//  * â•‘ + Simple, no synchronization issues                          â•‘
//  * â•‘ + Good for APIs, web servers                                 â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Cons:                                                         â•‘
//  * â•‘ - CPU-intensive tasks block everything                       â•‘
//  * â•‘ - Cannot utilize multiple CPU cores                          â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Example: GET /api/users â†’ query DB â†’ return (I/O-bound) âœ“    â•‘
//  * â•‘ Example: POST /compute â†’ fibonacci(40) â†’ BLOCKED âœ—           â•‘
//  * â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  * 
//  * â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
//  * â•‘ THREAD POOL (libuv, automatic)                                â•‘
//  * â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
//  * â•‘ Kiáº¿n trÃºc:  4 threads (managed by libuv)                      â•‘
//  * â•‘ Táº¡o cost:   Automatic, hidden                                 â•‘
//  * â•‘ Memory:     Medium                                            â•‘
//  * â•‘ Complexity: Low (you don't control it)                        â•‘
//  * â•‘ Use case:   File I/O, crypto, DNS                           â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Pros:                                                         â•‘
//  * â•‘ + Automatic, no manual management                            â•‘
//  * â•‘ + Good for file system operations                            â•‘
//  * â•‘ + Already included in Node.js                                â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Cons:                                                         â•‘
//  * â•‘ - Only 4 threads (limit)                                      â•‘
//  * â•‘ - Not configurable per request                               â•‘
//  * â•‘ - Limited to specific I/O operations                         â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Example: fs.readFile() â†’ dispatches to thread pool âœ“         â•‘
//  * â•‘ Example: Network I/O â†’ doesn't use thread pool âœ“             â•‘
//  * â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  * 
//  * â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
//  * â•‘ WORKER THREADS (Manual, on-demand)                            â•‘
//  * â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
//  * â•‘ Kiáº¿n trÃºc:  Manual creation, explicit control                 â•‘
//  * â•‘ Táº¡o cost:   ~30-40ms per thread creation                      â•‘
//  * â•‘ Memory:     High (~2MB per thread)                            â•‘
//  * â•‘ Complexity: Medium (you manage it)                            â•‘
//  * â•‘ Use case:   CPU-intensive tasks                              â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Pros:                                                         â•‘
//  * â•‘ + True parallelism (can use multiple cores)                  â•‘
//  * â•‘ + Doesn't block main thread                                  â•‘
//  * â•‘ + Can create many workers (N = CPU cores)                    â•‘
//  * â•‘ + Explicit control over lifecycle                            â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Cons:                                                         â•‘
//  * â•‘ - Creation/termination overhead (~30-40ms)                    â•‘
//  * â•‘ - Memory per thread (~2MB)                                    â•‘
//  * â•‘ - Data serialization overhead (unless SharedArrayBuffer)     â•‘
//  * â•‘ - Synchronization complexity                                 â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Example: Fibonacci(40) â†’ use worker âœ“                         â•‘
//  * â•‘ Example: Image processing â†’ use worker âœ“                      â•‘
//  * â•‘ Example: GET /api/users â†’ don't use worker âœ—                 â•‘
//  * â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  * 
//  * â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
//  * â•‘ CLUSTER (Process-based)                                       â•‘
//  * â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
//  * â•‘ Kiáº¿n trÃºc:  N worker processes + 1 master process            â•‘
//  * â•‘ Táº¡o cost:   High (~50-100ms per process)                      â•‘
//  * â•‘ Memory:     Very high (~40-60MB per process)                  â•‘
//  * â•‘ Complexity: High (IPC communication)                          â•‘
//  * â•‘ Use case:   Multi-core scaling for web servers              â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Pros:                                                         â•‘
//  * â•‘ + Utilize all CPU cores                                      â•‘
//  * â•‘ + Fault isolation (worker crash â‰  main crash)                â•‘
//  * â•‘ + Each worker is independent Node.js instance                â•‘
//  * â•‘ + Simple to implement (cluster module)                       â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Cons:                                                         â•‘
//  * â•‘ - High memory (40-60MB per worker)                            â•‘
//  * â•‘ - Slower creation (~50-100ms)                                 â•‘
//  * â•‘ - IPC overhead                                                â•‘
//  * â•‘ - Shared state management (need external DB/Redis)           â•‘
//  * â•‘                                                                â•‘
//  * â•‘ Example: Web server on 4-core CPU â†’ 4 cluster workers âœ“      â•‘
//  * â•‘ Example: 1000 fibonacci tasks â†’ cluster overkill âœ—           â•‘
//  * â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  * 
//  * CHá»ŒN CÃI NÃ€O?
//  * 
//  * I/O-bound (network, database):
//  * â†’ Main thread + async/await (best) âœ“
//  * 
//  * CPU-intensive task (1-100 tasks):
//  * â†’ Worker threads âœ“
//  * 
//  * Large data processing (images, video):
//  * â†’ Worker threads + SharedArrayBuffer âœ“
//  * 
//  * Web server scaling (4-core CPU):
//  * â†’ Cluster (4 workers) âœ“
//  * 
//  * Hybrid (I/O + CPU):
//  * â†’ Main thread + worker threads + cluster âœ“
//  */

// // ============================================================================
// // PHáº¦N 8: PERFORMANCE BENCHMARK
// // ============================================================================

// /**
//  * Ká»‹ch báº£n: TÃ­nh fibonacci(40) cho 100 requests
//  */

// class PerformanceBenchmark {
//   // Approach 1: Main thread (blocking)
//   async mainThreadApproach(): Promise<number> {
//     const tasks = Array.from({ length: 100 }, () => 40);
//     let total = 0;

//     for (const n of tasks) {
//       total += fibonacciSync(n);
//     }

//     return total;
//   }

//   // Approach 2: Single worker thread
//   async singleWorkerApproach(): Promise<number> {
//     const pool = new WorkerPool(
//       path.join(__dirname, 'fibonacci.worker.ts'),
//       1 // Single worker
//     );

//     const tasks = Array.from({ length: 100 }, () => ({ n: 40 }));
//     const results = await Promise.all(tasks.map(t => pool.runTask(t)));

//     pool.terminate();
//     return results.reduce((a, b) => a + b, 0);
//   }

//   // Approach 3: Worker pool (4 workers)
//   async workerPoolApproach(): Promise<number> {
//     const pool = new WorkerPool(
//       path.join(__dirname, 'fibonacci.worker.ts'),
//       4 // 4 workers
//     );

//     const tasks = Array.from({ length: 100 }, () => ({ n: 40 }));
//     const results = await Promise.all(tasks.map(t => pool.runTask(t)));

//     pool.terminate();
//     return results.reduce((a, b) => a + b, 0);
//   }

//   // Approach 4: Worker pool (8 workers)
//   async workerPool8Approach(): Promise<number> {
//     const pool = new WorkerPool(
//       path.join(__dirname, 'fibonacci.worker.ts'),
//       8 // 8 workers
//     );

//     const tasks = Array.from({ length: 100 }, () => ({ n: 40 }));
//     const results = await Promise.all(tasks.map(t => pool.runTask(t)));

//     pool.terminate();
//     return results.reduce((a, b) => a + b, 0);
//   }
// }

// /**
//  * Káº¿t quáº£ (Æ°á»›c tÃ­nh):
//  * 
//  * Fibonacci(40) â‰ˆ 1500ms (single calculation)
//  * 
//  * Main thread (blocking):
//  * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//  * â”‚ 100 Ã— 1500ms = 150 SECONDS!â”‚
//  * â”‚ âŒ Main thread BLOCKED    â”‚
//  * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//  * 
//  * Single worker (1 thread):
//  * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//  * â”‚ 100 Ã— 1500ms = 150 SECONDSâ”‚
//  * â”‚ âœ“ Main thread NOT blockedâ”‚
//  * â”‚ âŒ But still serial      â”‚
//  * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//  * 
//  * Worker pool (4 workers):
//  * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//  * â”‚ (100 / 4) Ã— 1500ms â‰ˆ    â”‚
//  * â”‚ 25 Ã— 1500ms = 37.5 SECONDSâ”‚
//  * â”‚ âœ“ Main thread NOT blockedâ”‚
//  * â”‚ âœ“ Parallel execution     â”‚
//  * â”‚ âœ“ 4x speedup            â”‚
//  * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//  * 
//  * Worker pool (8 workers on 8-core CPU):
//  * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//  * â”‚ (100 / 8) Ã— 1500ms â‰ˆ    â”‚
//  * â”‚ 12.5 Ã— 1500ms â‰ˆ 18.75 S â”‚
//  * â”‚ âœ“ Main thread NOT blockedâ”‚
//  * â”‚ âœ“ Better parallelism     â”‚
//  * â”‚ âœ“ 8x speedup            â”‚
//  * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//  * 
//  * SPEEDUP GRAPH:
//  * 
//  * Time (seconds)
//  * 160 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Main thread
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  * 140 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  * 120 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  * 100 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Single worker
//  *  80 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *  60 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
//  *  40 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ Pool(4)
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ
//  *  20 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ â–ˆ Pool(8)
//  *     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆ â–ˆ
//  *   0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
//  *     Main      Single  Pool Pool
//  *     Thread    Worker  4    8
//  * 
//  * Káº¿t luáº­n:
//  * - Main thread: Tá»’I (main blocked)
//  * - Single worker: BÃ¬nh thÆ°á»ng (no block, but slow)
//  * - Pool(4): Tá»T (good speedup)
//  * - Pool(8): Tá»Táº¤T (best on 8-core CPU)
//  */

// // ============================================================================
// // PHáº¦N 9: REAL-WORLD EXAMPLE - EXPRESS API WITH WORKERS
// // ============================================================================

// import express from 'express';

// const app = express();
// app.use(express.json());

// // Táº¡o worker pool cho CPU tasks
// const workerPool = new WorkerPool(
//   path.join(__dirname, 'fibonacci.worker.ts'),
//   4
// );

// // API endpoint: /api/fibonacci
// app.post('/api/fibonacci', async (req, res) => {
//   try {
//     const { n } = req.body;

//     if (!n || n < 0) {
//       return res.status(400).json({ error: 'Invalid input' });
//     }

//     // Sá»­ dá»¥ng worker thread Ä‘á»ƒ tÃ­nh fibonacci
//     const result = await workerPool.runTask({ n });

//     res.json({
//       n,
//       result,
//       timestamp: new Date().toISOString(),
//     });
//   } catch (error) {
//     res.status(500).json({
//       error: error instanceof Error ? error.message : 'Unknown error',
//     });
//   }
// });

// // API endpoint: /api/batch-fibonacci
// app.post('/api/batch-fibonacci', async (req, res) => {
//   try {
//     const { numbers } = req.body; // Array of numbers

//     if (!Array.isArray(numbers)) {
//       return res.status(400).json({ error: 'Invalid input' });
//     }

//     // Gá»­i táº¥t cáº£ tasks tá»›i worker pool
//     const results = await Promise.all(
//       numbers.map(n => workerPool.runTask({ n }))
//     );

//     res.json({
//       numbers,
//       results,
//       timestamp: new Date().toISOString(),
//     });
//   } catch (error) {
//     res.status(500).json({
//       error: error instanceof Error ? error.message : 'Unknown error',
//     });
//   }
// });

// /**
//  * Usage:
//  * 
//  * curl -X POST http://localhost:3000/api/fibonacci \
//  *   -H "Content-Type: application/json" \
//  *   -d '{"n": 40}'
//  * 
//  * Response: { n: 40, result: 102334155, timestamp: "..." }
//  * 
//  * 
//  * Benefit:
//  * - Main thread NOT blocked
//  * - Can serve other requests while fibonacci computes
//  * - If request comes while computing: add to queue, workers handle
//  */

// // ============================================================================
// // PHáº¦N 10: BEST PRACTICES
// // ============================================================================

// /**
//  * âœ“ BEST PRACTICES FOR WORKER THREADS:
//  * 
//  * 1. Reuse workers (use pools)
//  *    âœ“ Create pool once, reuse many times
//  *    âœ“ Creation cost: ~30-40ms per thread
//  *    âŒ Don't create new worker per task (overhead)
//  * 
//  * 2. Keep main thread processing
//  *    âœ“ Main thread handles HTTP requests, routing
//  *    âœ“ Worker threads handle CPU tasks
//  *    âŒ Don't let main thread do heavy computation
//  * 
//  * 3. Use async/await pattern
//  *    âœ“ Return Promise from worker operations
//  *    âœ“ Use async/await for clean code
//  * 
//  * 4. Handle errors properly
//  *    âœ“ Always handle 'error' event
//  *    âœ“ Implement timeout for stuck workers
//  *    âœ“ Terminate workers properly
//  * 
//  * 5. Monitor resource usage
//  *    âœ“ Number of workers â‰¤ CPU cores
//  *    âœ“ Monitor memory per worker
//  *    âœ“ Terminate unused workers
//  * 
//  * 6. Consider alternatives
//  *    âœ“ Cluster for web server scaling
//  *    âœ“ Async/await for I/O
//  *    âœ“ Only workers for CPU tasks
//  * 
//  * 7. Use SharedArrayBuffer carefully
//  *    âœ“ Only for large data (>10MB)
//  *    âœ“ Use Atomics for synchronization
//  *    âœ“ Be aware of security implications
//  * 
//  * 8. Profile and benchmark
//  *    âœ“ Measure actual performance
//  *    âœ“ Consider overhead (creation time)
//  *    âœ“ Test with realistic data sizes
//  */

// // ============================================================================
// // PHáº¦N 11: COMMON PITFALLS
// // ============================================================================

// /**
//  * âŒ PITFALL 1: Creating new worker for each task
//  */
// async function badApproach1() {
//   for (let i = 0; i < 1000; i++) {
//     // âŒ WRONG: 1000 workers created!
//     const worker = new Worker('./fibonacci.worker.ts');
//     worker.postMessage({ n: 40 });
//     // Memory: 1000 Ã— 2MB = 2GB! ğŸ’¥
//   }
// }

// async function goodApproach1() {
//   // âœ“ RIGHT: Reuse pool
//   const pool = new WorkerPool('./fibonacci.worker.ts', 4);

//   for (let i = 0; i < 1000; i++) {
//     await pool.runTask({ n: 40 });
//   }

//   pool.terminate();
// }

// /**
//  * âŒ PITFALL 2: Using workers for I/O tasks
//  */
// async function badApproach2() {
//   // âŒ WRONG: Worker for database query
//   const worker = new Worker('./db-query.worker.ts');
//   const result = await runTask(worker, { query: 'SELECT * FROM users' });
// }

// async function goodApproach2() {
//   // âœ“ RIGHT: Use async/await directly
//   const result = await db.query('SELECT * FROM users');
// }

// /**
//  * âŒ PITFALL 3: Not handling worker errors
//  */
// async function badApproach3() {
//   return new Promise(resolve => {
//     const worker = new Worker('./heavy.worker.ts');
//     worker.postMessage({ data: 'task' });

//     worker.on('message', result => {
//       resolve(result);
//     });
//     // âŒ No error handling! If worker crashes, promise never resolves
//   });
// }

// async function goodApproach3() {
//   return new Promise((resolve, reject) => {
//     const worker = new Worker('./heavy.worker.ts');
//     worker.postMessage({ data: 'task' });

//     worker.on('message', result => {
//       worker.terminate();
//       resolve(result);
//     });

//     worker.on('error', reject); // âœ“ Handle errors
//     worker.on('exit', code => {
//       // âœ“ Handle unexpected exit
//       if (code !== 0) {
//         reject(new Error(`Worker exited with code ${code}`));
//       }
//     });

//     // âœ“ Timeout
//     setTimeout(() => {
//       worker.terminate();
//       reject(new Error('Worker timeout'));
//     }, 10000);
//   });
// }

// /**
//  * âŒ PITFALL 4: Large data copying
//  */
// async function badApproach4() {
//   const largeData = new Array(10000000).fill('x'); // 10MB array

//   // âŒ WRONG: Copying 10MB data for each task!
//   const worker = new Worker('./processor.worker.ts');
//   worker.postMessage({ data: largeData }); // Structured clone = slow
// }

// async function goodApproach4() {
//   const largeData = new ArrayBuffer(10 * 1024 * 1024); // 10MB buffer

//   // âœ“ RIGHT: Transfer ownership (not copy)
//   const worker = new Worker('./processor.worker.ts');
//   worker.postMessage(
//     { buffer: largeData },
//     [largeData] // transferList = transfer ownership
//   );
//   // largeData is now inaccessible in main thread
//   // Worker owns it, no copying!
// }

// /**
//  * âŒ PITFALL 5: Not terminating workers
//  */
// async function badApproach5() {
//   const worker = new Worker('./fibonacci.worker.ts');
//   await runTask(worker, { n: 40 });
//   // âŒ WRONG: Worker still running in background, consuming memory!
// }

// async function goodApproach5() {
//   const worker = new Worker('./fibonacci.worker.ts');
//   const result = await runTask(worker, { n: 40 });
//   worker.terminate(); // âœ“ Free resources
// }

// // ============================================================================
// // PHáº¦N 12: ADVANCED - WORKER LIFECYCLE
// // ============================================================================

// /**
//  * Worker Lifecycle:
//  * 
//  * new Worker(filename)
//  *     â†“
//  * Worker thread started
//  *     â†“
//  * worker.postMessage(data)  â† Send data
//  *     â†“
//  * worker processes data
//  *     â†“
//  * worker.postMessage(result) â† Send back
//  *     â†“
//  * Main thread receives message
//  *     â†“
//  * worker.terminate()
//  *     â†“
//  * Worker thread stopped
//  * (memory freed)
//  */

// function advancedWorkerExample() {
//   const worker = new Worker('./task.worker.ts');

//   // 1. Set up listeners BEFORE sending data
//   worker.on('message', (message: any) => {
//     console.log('Progress:', message);
//   });

//   worker.on('error', (error: Error) => {
//     console.error('Worker error:', error);
//   });

//   worker.on('exit', (code: number) => {
//     if (code !== 0) {
//       console.error(`Worker stopped with exit code ${code}`);
//     }
//   });

//   // 2. Send message
//   worker.postMessage({
//     command: 'PROCESS',
//     data: { /* ... */ },
//   });

//   // 3. Worker can send multiple messages (progress)
//   // 4. Main thread can send multiple messages to worker

//   // 5. When done, terminate
//   // worker.terminate();
// }

// /**
//  * Worker can handle multiple message exchanges:
//  * 
//  * Main thread â†’ Worker: "Start processing"
//  * Worker â†’ Main thread: "Progress: 25%"
//  * Worker â†’ Main thread: "Progress: 50%"
//  * Worker â†’ Main thread: "Progress: 75%"
//  * Worker â†’ Main thread: "Completed: result"
//  * Main thread â†’ Worker: "terminate"
//  * Worker thread stopped
//  */

// // ============================================================================
// // PHáº¦N 13: TÃ“MLá»šP
// // ============================================================================

// /**
//  * WORKER THREADS SUMMARY:
//  * 
//  * âœ“ LÃ  gÃ¬:
//  *   Multiple V8 instances cháº¡y trong cÃ¹ng má»™t Node.js process
//  * 
//  * âœ“ Khi dÃ¹ng:
//  *   CPU-intensive tasks (fibonacci, image processing, etc)
//  * 
//  * âœ“ Khi KHÃ”NG dÃ¹ng:
//  *   I/O-bound (database, network) - dÃ¹ng async/await
//  * 
//  * âœ“ CÃ¡ch táº¡o:
//  *   new Worker(filename)
//  * 
//  * âœ“ Giao tiáº¿p:
//  *   postMessage() vÃ  parentPort.on('message')
//  * 
//  * âœ“ Performance:
//  *   Creation: ~30-40ms
//  *   Memory: ~2MB per thread
//  *   Parallelism: True (uses multiple CPU cores)
//  * 
//  * âœ“ Best practice:
//  *   Use worker pools, don't create per-task
//  * 
//  * âœ“ Alternatives:
//  *   Thread pool (automatic, limited)
//  *   Cluster (process-based, scales web servers)
//  *   Main thread (for I/O-bound)
//  */

// console.log('=== WORKER THREADS GUIDE COMPLETED ===');
